{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-05T12:01:08.728642Z",
     "iopub.status.busy": "2025-09-05T12:01:08.728421Z",
     "iopub.status.idle": "2025-09-05T12:01:09.975089Z",
     "shell.execute_reply": "2025-09-05T12:01:09.974285Z",
     "shell.execute_reply.started": "2025-09-05T12:01:08.728623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:01:09.977012Z",
     "iopub.status.busy": "2025-09-05T12:01:09.976405Z",
     "iopub.status.idle": "2025-09-05T12:01:10.192808Z",
     "shell.execute_reply": "2025-09-05T12:01:10.19181Z",
     "shell.execute_reply.started": "2025-09-05T12:01:09.976983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HF_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:01:10.194305Z",
     "iopub.status.busy": "2025-09-05T12:01:10.194016Z",
     "iopub.status.idle": "2025-09-05T12:01:59.803531Z",
     "shell.execute_reply": "2025-09-05T12:01:59.801781Z",
     "shell.execute_reply.started": "2025-09-05T12:01:10.194282Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mt200\\.cache\\huggingface\\hub\\models--google--embeddinggemma-300m. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Get Hugging Face token from Kaggle secret\n",
    "hf_token = HF_TOKEN\n",
    "\n",
    "model_name = \"google/embeddinggemma-300m\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, trust_remote_code=True) \n",
    "model = AutoModel.from_pretrained(model_name, token=hf_token, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:01:59.805152Z",
     "iopub.status.busy": "2025-09-05T12:01:59.80451Z",
     "iopub.status.idle": "2025-09-05T12:01:59.811493Z",
     "shell.execute_reply": "2025-09-05T12:01:59.810351Z",
     "shell.execute_reply.started": "2025-09-05T12:01:59.805132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_l_video(video_id: str) -> str:\n",
    "    l_video = video_id[:3]\n",
    "    \n",
    "    return l_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:01:59.814258Z",
     "iopub.status.busy": "2025-09-05T12:01:59.813972Z",
     "iopub.status.idle": "2025-09-05T12:02:00.095469Z",
     "shell.execute_reply": "2025-09-05T12:02:00.094177Z",
     "shell.execute_reply.started": "2025-09-05T12:01:59.81424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def _safe_parse_entities(x):\n",
    "    \"\"\"Parse entities JSON string safely.\"\"\"\n",
    "    try:\n",
    "        if isinstance(x, str):\n",
    "            return json.loads(x)\n",
    "        return x if isinstance(x, dict) else {}\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def safe_read_json(path):\n",
    "    \"\"\"Read a JSON file safely. Return empty dict if file not found.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return {}\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f)\n",
    "    except Exception:\n",
    "        print(f\"ERORR {path}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def safe_read_csv(path, **kwargs):\n",
    "    \"\"\"Read a CSV file safely. Return empty DataFrame if file not found.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        return pd.read_csv(path, **kwargs)\n",
    "    except Exception:\n",
    "        print(f\"ERORR {path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def build_keyframes_json(base_dir, video_id):\n",
    "    \"\"\"\n",
    "    Tạo danh sách JSON keyframe cho một video (thêm ASR enriched).\n",
    "    \"\"\"\n",
    "    # === Load metadata ===\n",
    "    meta_path = os.path.join(\n",
    "        \"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/btc-b2/media-info-aic25-b2/media-info\",\n",
    "        f\"{video_id}.json\"\n",
    "    )\n",
    "    meta_raw = safe_read_json(meta_path)\n",
    "\n",
    "    l_video = get_l_video(video_id)\n",
    "    l_video_link = l_video\n",
    "\n",
    "    asr_enrich_path = os.path.join(\n",
    "        \"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/asr/output\", f\"{video_id}_segments_enriched.csv\"\n",
    "    )\n",
    "    asr_enrich_df = safe_read_csv(asr_enrich_path)\n",
    "\n",
    "    # Ensure columns\n",
    "    for col, default in [\n",
    "        (\"labels_vi\", \"\"),\n",
    "        (\"entities\", \"{}\"),\n",
    "        (\"text_corrected\", \"\"),\n",
    "    ]:\n",
    "        if col not in asr_enrich_df.columns:\n",
    "            asr_enrich_df[col] = default\n",
    "        asr_enrich_df[col] = asr_enrich_df[col].fillna(default)\n",
    "\n",
    "    asr_enrich_df[\"start\"] = pd.to_numeric(asr_enrich_df.get(\"start\", pd.NA), errors=\"coerce\")\n",
    "    asr_enrich_df[\"end\"] = pd.to_numeric(asr_enrich_df.get(\"end\", pd.NA), errors=\"coerce\")\n",
    "    asr_enrich_df[\"entities_dict\"] = asr_enrich_df[\"entities\"].apply(_safe_parse_entities)\n",
    "\n",
    "    # === Load OCR ===\n",
    "    ocr_path = f\"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/ocr/{video_id}.csv\"\n",
    "    ocr_df = safe_read_csv(ocr_path, encoding=\"utf-16\")\n",
    "    if not ocr_df.empty:\n",
    "        ocr_df[\"response\"] = ocr_df[\"response\"].fillna(\"\")\n",
    "        ocr_df[\"kf_idx\"] = (\n",
    "            ocr_df[\"keyframe\"].str.replace(\".jpg\", \"\", regex=False).astype(str).str.zfill(3)\n",
    "        )\n",
    "        ocr_map = dict(zip(ocr_df[\"kf_idx\"], ocr_df[\"response\"]))\n",
    "    else:\n",
    "        ocr_map = {}\n",
    "\n",
    "    # === Load keyframes ===\n",
    "    kf_path = os.path.join(\n",
    "        \"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/btc-b2/map-keyframes-b2/map-keyframes-b2\", f\"{video_id}.csv\"\n",
    "    )\n",
    "    kf_df = safe_read_csv(kf_path)\n",
    "    if kf_df.empty:\n",
    "        return \"\"  # No keyframes => return empty string\n",
    "\n",
    "    results = []\n",
    "    for _, row in kf_df.iterrows():\n",
    "        n_keyframe = int(row[\"n\"])\n",
    "        frame_idx = int(row[\"frame_idx\"])\n",
    "        fps = int(row[\"fps\"])\n",
    "        pts_time = float(row[\"pts_time\"])\n",
    "        ts = f\"{int(pts_time//3600):02d}:{int((pts_time%3600)//60):02d}:{int(pts_time%60):02d}\"\n",
    "\n",
    "        # === Match ASR enriched ===\n",
    "        match_rows = asr_enrich_df[\n",
    "            (asr_enrich_df[\"start\"] <= pts_time) & (asr_enrich_df[\"end\"] >= pts_time)\n",
    "        ]\n",
    "        asr_text = match_rows[\"text_corrected\"].iloc[0] if not match_rows.empty else \"\"\n",
    "        sound = match_rows[\"labels_vi\"].iloc[0] if not match_rows.empty else \"\"\n",
    "        entities = match_rows[\"entities_dict\"].iloc[0] if not match_rows.empty else {}\n",
    "\n",
    "        # === Match OCR ===\n",
    "        kf_idx_str = f\"{n_keyframe:03}\"\n",
    "        ocr_text = ocr_map.get(kf_idx_str, \"\")\n",
    "\n",
    "        # === Object detections ===\n",
    "        obj_path = f\"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/object/processing_objects/{video_id}/{n_keyframe:03}.csv\"\n",
    "        objects = []\n",
    "        obj_df = safe_read_csv(obj_path)\n",
    "        if not obj_df.empty:\n",
    "            for _, obj in obj_df.iterrows():\n",
    "                obj_id_raw = str(obj[\"object_id\"])\n",
    "                match = re.match(r\"(.+?)_(\\d+)$\", obj_id_raw)\n",
    "                if match:\n",
    "                    obj_name = match.group(1)\n",
    "                    obj_num = int(match.group(2))\n",
    "                else:\n",
    "                    obj_name = obj_id_raw\n",
    "                    obj_num = None\n",
    "\n",
    "                objects.append({\n",
    "                    \"name\": obj_name,\n",
    "                    \"id\": obj_num,\n",
    "                    \"score\": float(obj[\"score\"]),\n",
    "                    \"bbox\": [float(obj[\"x_min\"]), float(obj[\"y_min\"]), float(obj[\"x_max\"]), float(obj[\"y_max\"])],\n",
    "                    \"center\": [float(obj[\"x_center\"]), float(obj[\"y_center\"])],\n",
    "                    \"color\": obj.get(\"color\", \"\")\n",
    "                })\n",
    "\n",
    "        # === Build JSON record ===\n",
    "        record = {\n",
    "            \"id\": f\"{video_id}_F{n_keyframe:03}\",\n",
    "            \"video_id\": video_id,\n",
    "            \"timestamp\": ts,\n",
    "            \"fps\": fps,\n",
    "            \"n_keyframe\": n_keyframe,\n",
    "            \"frame_idx\": frame_idx,\n",
    "            \"image_url\": f\"https://storage.googleapis.com/test-video-retrieval/dataset/unzips_b2/Keyframes_{l_video}/keyframes/{video_id}/{n_keyframe:03}.jpg\",\n",
    "            \"video_url\": (\n",
    "                f\"https://storage.googleapis.com/test-video-retrieval/dataset/unzips_b2/\"\n",
    "                f\"Videos_{l_video}/video/{video_id}.mp4\"\n",
    "            ),\n",
    "            \"objects\": objects,\n",
    "            \"sound\": sound,\n",
    "            \"entities\": entities,\n",
    "            \"title\": meta_raw.get(\"title\"),\n",
    "            \"author\": meta_raw.get(\"author\"),\n",
    "            \"keyword\": meta_raw.get(\"keywords\"),\n",
    "            \"length\": meta_raw.get(\"length\"),\n",
    "            \"publish_date\": meta_raw.get(\"publish_date\"),\n",
    "            \"duration\": meta_raw.get(\"length\"),\n",
    "            \"channel_url\": meta_raw.get(\"channel_url\"),\n",
    "            \"watch_url\": meta_raw.get(\"watch_url\"),\n",
    "            \"thumbnail_url\": meta_raw.get(\"thumbnail_url\"),\n",
    "            \"asr_text\": asr_text,\n",
    "            \"ocr_text\": ocr_text,\n",
    "        }\n",
    "        results.append(record)\n",
    "\n",
    "    return results if results else \"\"  # Return \"\" if no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:02:00.096516Z",
     "iopub.status.busy": "2025-09-05T12:02:00.096243Z",
     "iopub.status.idle": "2025-09-05T12:02:05.148097Z",
     "shell.execute_reply": "2025-09-05T12:02:05.147113Z",
     "shell.execute_reply.started": "2025-09-05T12:02:00.096486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'K01_V001_F001', 'video_id': 'K01_V001', 'timestamp': '00:00:00', 'fps': 25, 'n_keyframe': 1, 'frame_idx': 0, 'image_url': 'https://storage.googleapis.com/test-video-retrieval/dataset/unzips_b2/Keyframes_K01/keyframes/K01_V001/001.jpg', 'video_url': 'https://storage.googleapis.com/test-video-retrieval/dataset/unzips_b2/Videos_K01/video/K01_V001.mp4', 'objects': [{'name': 'Lantern', 'id': 1, 'score': 0.67, 'bbox': [0.37, 0.47, 0.47, 0.64], 'center': [0.42, 0.56], 'color': 'Orange'}, {'name': 'Lantern', 'id': 2, 'score': 0.66, 'bbox': [0.53, 0.38, 0.72, 0.73], 'center': [0.62, 0.56], 'color': 'Orange'}, {'name': 'Skyscraper', 'id': 1, 'score': 0.65, 'bbox': [0.82, 0.4, 0.88, 0.62], 'center': [0.85, 0.51], 'color': 'Black'}, {'name': 'Skyscraper', 'id': 2, 'score': 0.64, 'bbox': [0.03, 0.41, 0.1, 0.63], 'center': [0.06, 0.52], 'color': 'Gray'}, {'name': 'Skyscraper', 'id': 3, 'score': 0.56, 'bbox': [0.71, 0.45, 0.77, 0.62], 'center': [0.74, 0.54], 'color': 'Black'}, {'name': 'Skyscraper', 'id': 4, 'score': 0.54, 'bbox': [0.34, 0.39, 0.39, 0.61], 'center': [0.37, 0.5], 'color': 'Orange'}], 'sound': 'Âm nhạc(0.73); Hợp xướng(0.03)', 'entities': {}, 'title': '60 Giây Chiều - Ngày 01/10/2024 - HTV Tin Tức Mới Nhất 2024', 'author': '60 Giây Official', 'keyword': ['HTV Tin tức', 'HTV News', 'chuong trinh 60 giay', 'chuong trinh 60s', 'ban tin 60 giay', 'ban tin 60s', '60 giay', '60s', '60 giay hom nay', 'Tin tức 60 giây', 'TIN TUC 60 GIAY', 'TIN TỨC 60 GI Y', 'tin tuc 60 giay', 'tin tức', '60 giây', 'Tin Tức', 'TIN TUC', '60 GIAY', 'Tin Tức Mới', 'Tin Tức Mới Nhất', '60 Giây', 'HTV Tin Tức', 'HTV news', 'Xem tin tức mới nhất', 'Xem tin tức', 'Hôm nay xem gì', '60 giây Sáng', '60 giây chiều', 'Bản tin 60s', 'Tin tức thời sự việt nam', 'Tin tuc thoi su Viet nam'], 'length': 1050, 'publish_date': '02/10/2024', 'duration': 1050, 'channel_url': 'https://www.youtube.com/channel/UCRjzfa1E0gA50lvDQipbDMg', 'watch_url': 'https://youtube.com/watch?v=ls1EfyBswW8', 'thumbnail_url': 'https://i.ytimg.com/vi/ls1EfyBswW8/sddefault.jpg?v=66fcd843', 'asr_text': '', 'ocr_text': 'Hình ảnh là một bức tranh toàn cảnh thành phố với bầu trời hoàng hôn rực lửa, ánh sáng lung linhung. Ở trung tâm của hình có hai vòng lặp màu vàng cam đậm nhạt tạo nên hiệu ứng như mặt Trái Đất phản chiếu vào nguồn điện năng lượng xanh từ hồ nước phía trước và các tòa nhà chọc hàng đầu ở xa hơn về chiều cao soi xuống dưới cùng bên phải (có thể thấy rõ). Trên đỉnh mỗi vầng đồng đều hiển thị logo \"giây\" được viết bằng chữ in hoa cách điệu trên nền trắng mờ phẳng trong suốt giữa dòng chảy sông hoặc kênh nhỏ chạy dâu qua khu vực này.\\n\\nBên cạnh đó còn xuất hiện những ngôi saucé lớn nằm ngang gần bến cảng đang hoạt động cho đến khi tối đen bắt lên chân đất.'}\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/\"\n",
    "video_id = \"K01_V001\"\n",
    "\n",
    "keyframes_metadata = build_keyframes_json(base_dir, video_id)\n",
    "\n",
    "# In ra một keyframe ví dụ\n",
    "print(keyframes_metadata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"K01_V001_F004\",\n",
      "  \"video_id\": \"K01_V001\",\n",
      "  \"timestamp\": \"00:00:12\",\n",
      "  \"fps\": 25,\n",
      "  \"n_keyframe\": 4,\n",
      "  \"frame_idx\": 300,\n",
      "  \"image_url\": \"https://storage.googleapis.com/test-video-retrieval/dataset/unzips_b2/Keyframes_K01/keyframes/K01_V001/004.jpg\",\n",
      "  \"video_url\": \"https://storage.googleapis.com/test-video-retrieval/dataset/unzips_b2/Videos_K01/video/K01_V001.mp4\",\n",
      "  \"objects\": [\n",
      "    {\n",
      "      \"name\": \"Lantern\",\n",
      "      \"id\": 1,\n",
      "      \"score\": 0.75,\n",
      "      \"bbox\": [\n",
      "        0.03,\n",
      "        0.05,\n",
      "        0.83,\n",
      "        0.98\n",
      "      ],\n",
      "      \"center\": [\n",
      "        0.43,\n",
      "        0.51\n",
      "      ],\n",
      "      \"color\": \"Red\"\n",
      "    }\n",
      "  ],\n",
      "  \"sound\": \"Lời nói(0.53); Âm nhạc(0.35)\",\n",
      "  \"entities\": {},\n",
      "  \"title\": \"60 Giây Chiều - Ngày 01/10/2024 - HTV Tin Tức Mới Nhất 2024\",\n",
      "  \"author\": \"60 Giây Official\",\n",
      "  \"keyword\": [\n",
      "    \"HTV Tin tức\",\n",
      "    \"HTV News\",\n",
      "    \"chuong trinh 60 giay\",\n",
      "    \"chuong trinh 60s\",\n",
      "    \"ban tin 60 giay\",\n",
      "    \"ban tin 60s\",\n",
      "    \"60 giay\",\n",
      "    \"60s\",\n",
      "    \"60 giay hom nay\",\n",
      "    \"Tin tức 60 giây\",\n",
      "    \"TIN TUC 60 GIAY\",\n",
      "    \"TIN TỨC 60 GI Y\",\n",
      "    \"tin tuc 60 giay\",\n",
      "    \"tin tức\",\n",
      "    \"60 giây\",\n",
      "    \"Tin Tức\",\n",
      "    \"TIN TUC\",\n",
      "    \"60 GIAY\",\n",
      "    \"Tin Tức Mới\",\n",
      "    \"Tin Tức Mới Nhất\",\n",
      "    \"60 Giây\",\n",
      "    \"HTV Tin Tức\",\n",
      "    \"HTV news\",\n",
      "    \"Xem tin tức mới nhất\",\n",
      "    \"Xem tin tức\",\n",
      "    \"Hôm nay xem gì\",\n",
      "    \"60 giây Sáng\",\n",
      "    \"60 giây chiều\",\n",
      "    \"Bản tin 60s\",\n",
      "    \"Tin tức thời sự việt nam\",\n",
      "    \"Tin tuc thoi su Viet nam\"\n",
      "  ],\n",
      "  \"length\": 1050,\n",
      "  \"publish_date\": \"02/10/2024\",\n",
      "  \"duration\": 1050,\n",
      "  \"channel_url\": \"https://www.youtube.com/channel/UCRjzfa1E0gA50lvDQipbDMg\",\n",
      "  \"watch_url\": \"https://youtube.com/watch?v=ls1EfyBswW8\",\n",
      "  \"thumbnail_url\": \"https://i.ytimg.com/vi/ls1EfyBswW8/sddefault.jpg?v=66fcd843\",\n",
      "  \"asr_text\": \"Lũ gây sạt lở, cô lập hoàn toàn bốn bản, khẩn trương khắc phục hậu quả sau lũ.\",\n",
      "  \"ocr_text\": \"Hình ảnh là một phần của chương trình truyền hình HTV7, với nền trắng và các chấm sáng màu đỏ.  Chất liệu có vẻ như được làm từ kim loại hoặc nhựa cứng sáp nhập lại nhau tạo thành những đường cong mềm mại ở giữa hai bên trái màn phát sóng (có thể thấy rõ ràng). Các điểm nhấn chính bao gồm: \\n* **Màn phim:** Một tấm gương lớn hiển thị toàn bộ bản đồ thế giới bằng đèn LED nhỏ li ti trên bề mặt kính cường lực phản chiếu ánh nắng tự nhiên.\\n**Chữ viết trong logo TV VTV18 HD**: Logo này nằm phía góc phải dưới cùng gần trung tâm bức tranh nhưng không đủ nổi bật để đọc đầy đặn.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(keyframes_metadata[3], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:02:05.149245Z",
     "iopub.status.busy": "2025-09-05T12:02:05.148969Z",
     "iopub.status.idle": "2025-09-05T12:02:05.156826Z",
     "shell.execute_reply": "2025-09-05T12:02:05.155345Z",
     "shell.execute_reply.started": "2025-09-05T12:02:05.149219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_text_embedding(text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state  # (batch, seq_len, hidden)\n",
    "\n",
    "        # Attention mask để bỏ padding\n",
    "        mask = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size())\n",
    "        masked_embeddings = last_hidden_state * mask\n",
    "\n",
    "        # Mean pooling\n",
    "        sum_embeddings = masked_embeddings.sum(dim=1)\n",
    "        sum_mask = mask.sum(dim=1)\n",
    "        embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "        emb = embeddings[0].cpu().numpy().tolist()\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:02:05.158429Z",
     "iopub.status.busy": "2025-09-05T12:02:05.158095Z",
     "iopub.status.idle": "2025-09-05T12:02:06.141744Z",
     "shell.execute_reply": "2025-09-05T12:02:06.14019Z",
     "shell.execute_reply.started": "2025-09-05T12:02:05.158397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm chuyển số thứ tự sang chữ tiếng Việt\n",
    "def number_to_vietnamese_order(n):\n",
    "    units = [\"\", \"một\", \"hai\", \"ba\", \"bốn\", \"năm\", \"sáu\", \"bảy\", \"tám\", \"chín\"]\n",
    "    tens = [\"\", \"mười\", \"hai mươi\", \"ba mươi\", \"bốn mươi\", \"năm mươi\",\n",
    "            \"sáu mươi\", \"bảy mươi\", \"tám mươi\", \"chín mươi\"]\n",
    "\n",
    "    if n <= 10:\n",
    "        first10 = [\"thứ nhất\", \"thứ hai\", \"thứ ba\", \"thứ tư\", \"thứ năm\",\n",
    "                   \"thứ sáu\", \"thứ bảy\", \"thứ tám\", \"thứ chín\", \"thứ mười\"]\n",
    "        return first10[n-1]\n",
    "\n",
    "    ten = n // 10\n",
    "    unit = n % 10\n",
    "\n",
    "    if ten == 1:\n",
    "        text = \"mười\"\n",
    "    else:\n",
    "        text = tens[ten]\n",
    "\n",
    "    if unit == 0:\n",
    "        order_text = f\"thứ {text}\"\n",
    "    elif unit == 1 and ten > 1:\n",
    "        order_text = f\"thứ {text} mốt\"\n",
    "    elif unit == 5:\n",
    "        order_text = f\"thứ {text} lăm\"\n",
    "    else:\n",
    "        order_text = f\"thứ {text} {units[unit]}\"\n",
    "\n",
    "    return order_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:02:06.142889Z",
     "iopub.status.busy": "2025-09-05T12:02:06.142621Z",
     "iopub.status.idle": "2025-09-05T12:02:06.199681Z",
     "shell.execute_reply": "2025-09-05T12:02:06.198518Z",
     "shell.execute_reply.started": "2025-09-05T12:02:06.142873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class_name</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Accordion</td>\n",
       "      <td>Đàn phong cầm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Adhesive tape</td>\n",
       "      <td>Băng dính</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>Thiết bị bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Airplane</td>\n",
       "      <td>Máy bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alarm clock</td>\n",
       "      <td>Đồng hồ báo thức</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>Woodpecker</td>\n",
       "      <td>Chim gõ kiến</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>Worm</td>\n",
       "      <td>Con giun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>582</td>\n",
       "      <td>Wrench</td>\n",
       "      <td>Cờ lê</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>583</td>\n",
       "      <td>Zebra</td>\n",
       "      <td>Ngựa vằn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>584</td>\n",
       "      <td>Zucchini</td>\n",
       "      <td>Bí ngòi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     class_name       translation\n",
       "0      1      Accordion     Đàn phong cầm\n",
       "1      2  Adhesive tape         Băng dính\n",
       "2      3       Aircraft      Thiết bị bay\n",
       "3      4       Airplane           Máy bay\n",
       "4      5    Alarm clock  Đồng hồ báo thức\n",
       "..   ...            ...               ...\n",
       "579  580     Woodpecker      Chim gõ kiến\n",
       "580  581           Worm          Con giun\n",
       "581  582         Wrench             Cờ lê\n",
       "582  583          Zebra          Ngựa vằn\n",
       "583  584       Zucchini           Bí ngòi\n",
       "\n",
       "[584 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_label = pd.read_csv(\"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/object-detection/unique_classes_vi.csv\")\n",
    "object_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:02:06.200842Z",
     "iopub.status.busy": "2025-09-05T12:02:06.200551Z",
     "iopub.status.idle": "2025-09-05T12:02:06.206381Z",
     "shell.execute_reply": "2025-09-05T12:02:06.205015Z",
     "shell.execute_reply.started": "2025-09-05T12:02:06.200813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "OBJ_NAME_MAP = dict(zip(object_label[\"class_name\"], object_label[\"translation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:02:06.207696Z",
     "iopub.status.busy": "2025-09-05T12:02:06.207354Z",
     "iopub.status.idle": "2025-09-05T12:02:06.228392Z",
     "shell.execute_reply": "2025-09-05T12:02:06.227409Z",
     "shell.execute_reply.started": "2025-09-05T12:02:06.207667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mapping màu\n",
    "COLOR_MAP = {\n",
    "    \"Gray\": \"Xám\",\n",
    "    \"Black\": \"Đen\",\n",
    "    \"White\": \"Trắng\",\n",
    "    \"Red\": \"Đỏ\",\n",
    "    \"Blue\": \"Xanh dương\",\n",
    "    \"Green\": \"Xanh lá\",\n",
    "    \"Yellow\": \"Vàng\",\n",
    "    \"Brown\": \"Nâu\",\n",
    "    \"Orange\": \"Cam\",\n",
    "    \"Pink\": \"Hồng\",\n",
    "    \"Purple\": \"Tím\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:03:54.035963Z",
     "iopub.status.busy": "2025-09-05T12:03:54.035593Z",
     "iopub.status.idle": "2025-09-05T12:03:54.046631Z",
     "shell.execute_reply": "2025-09-05T12:03:54.044966Z",
     "shell.execute_reply.started": "2025-09-05T12:03:54.035938Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_text_for_embedding(kf, img_w=1.0, img_h=1.0):\n",
    "    objs = kf.get(\"objects\", [])\n",
    "    natural_objects_desc = \"\"\n",
    "\n",
    "    if objs:\n",
    "        # Áp dụng mapping tên object\n",
    "        names_mapped = [\n",
    "            OBJ_NAME_MAP.get(o.get(\"name\", \"Unknown\"), o.get(\"name\", \"Unknown\"))\n",
    "            for o in objs\n",
    "        ]\n",
    "        counts = Counter(names_mapped)\n",
    "\n",
    "        # Gom nhóm thành câu văn\n",
    "        obj_sentences = []\n",
    "        for name, count in counts.items():\n",
    "            if count == 1:\n",
    "                obj_sentences.append(f\"một {name.lower()}\")\n",
    "            elif count <= 6:\n",
    "                obj_sentences.append(f\"{count} {name.lower()}\")\n",
    "            else:\n",
    "                obj_sentences.append(f\"nhiều {name.lower()}\")\n",
    "\n",
    "        natural_objects_desc = \", \".join(obj_sentences)\n",
    "\n",
    "    # Mô tả âm thanh\n",
    "    sound_desc = kf.get(\"sound\", \"\")\n",
    "    sound_text = f\"Có tiếng: {sound_desc.lower()}\" if sound_desc else \"\"\n",
    "\n",
    "    # Nội dung OCR + ASR\n",
    "    ocr_text = kf.get(\"ocr_text\", \"\").strip()\n",
    "    asr_text = kf.get(\"asr_text\", \"\").strip()\n",
    "    text_parts = []\n",
    "\n",
    "    if ocr_text:\n",
    "        text_parts.append(f\"{ocr_text}\")\n",
    "    if asr_text:\n",
    "        text_parts.append(f\"Video có đoạn thoại: {asr_text}\")\n",
    "\n",
    "    context_text = \" \".join(text_parts)\n",
    "\n",
    "    # Tiêu đề video\n",
    "    title = kf.get(\"title\", \"\").strip()\n",
    "    title_text = f\"Video: {title}\" if title else \"\"\n",
    "\n",
    "    # Gộp lại thành đoạn văn tự nhiên\n",
    "    combined = f\"\"\"\n",
    "{title_text}.\n",
    "Hình ảnh chứa {natural_objects_desc if natural_objects_desc else \"không rõ vật thể nổi bật\"}.\n",
    "{sound_text}.\n",
    "{context_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    # Làm gọn câu, bỏ dòng trống thừa\n",
    "    combined = \" \".join(combined.split())\n",
    "    # print(combined)\n",
    "    # print(\"=================================\")\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duyệt qua các file video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T12:02:06.264127Z",
     "iopub.status.busy": "2025-09-05T12:02:06.263717Z",
     "iopub.status.idle": "2025-09-05T12:02:06.32746Z",
     "shell.execute_reply": "2025-09-05T12:02:06.326697Z",
     "shell.execute_reply.started": "2025-09-05T12:02:06.2641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video IDs: ['K01_V001', 'K01_V002', 'K01_V003', 'K01_V004', 'K01_V005', 'K01_V006', 'K01_V007', 'K01_V008', 'K01_V009', 'K01_V010', 'K01_V011', 'K01_V012', 'K01_V013', 'K01_V014', 'K01_V015', 'K01_V016', 'K01_V017', 'K01_V018', 'K01_V019', 'K01_V020', 'K01_V021', 'K01_V022', 'K01_V023', 'K01_V024', 'K01_V025', 'K01_V026', 'K01_V027', 'K01_V028', 'K01_V029', 'K01_V030', 'K01_V031', 'K02_V001', 'K02_V002', 'K02_V003', 'K02_V004', 'K02_V005', 'K02_V006', 'K02_V007', 'K02_V008', 'K02_V009', 'K02_V010', 'K02_V011', 'K02_V012', 'K02_V013', 'K02_V014', 'K02_V015', 'K02_V016', 'K02_V017', 'K02_V018', 'K02_V019', 'K02_V020', 'K02_V021', 'K02_V022', 'K02_V023', 'K02_V024', 'K02_V025', 'K02_V026', 'K02_V027', 'K02_V028', 'K02_V029', 'K02_V030', 'K02_V031', 'K03_V001', 'K03_V002', 'K03_V003', 'K03_V004', 'K03_V005', 'K03_V006', 'K03_V007', 'K03_V008', 'K03_V009', 'K03_V010', 'K03_V011', 'K03_V012', 'K03_V013', 'K03_V014', 'K03_V015', 'K03_V016', 'K03_V017', 'K03_V018', 'K03_V019', 'K03_V020', 'K03_V021', 'K03_V022', 'K03_V023', 'K03_V024', 'K03_V025', 'K03_V026', 'K03_V027', 'K03_V028', 'K03_V029', 'K04_V001', 'K04_V002', 'K04_V003', 'K04_V004', 'K04_V005', 'K04_V006', 'K04_V007', 'K04_V008', 'K04_V009', 'K04_V010', 'K04_V011', 'K04_V012', 'K04_V013', 'K04_V014', 'K04_V015', 'K04_V016', 'K04_V017', 'K04_V018', 'K04_V019', 'K04_V020', 'K04_V021', 'K04_V022', 'K04_V023', 'K04_V024', 'K04_V025', 'K04_V026', 'K04_V027', 'K04_V028', 'K04_V029', 'K04_V030', 'K05_V001', 'K05_V002', 'K05_V003', 'K05_V004', 'K05_V005', 'K05_V006', 'K05_V007', 'K05_V008', 'K05_V009', 'K05_V010', 'K05_V011', 'K05_V012', 'K05_V013', 'K05_V014', 'K05_V015', 'K05_V016', 'K05_V017', 'K05_V018', 'K05_V019', 'K05_V020', 'K05_V021', 'K05_V022', 'K05_V023', 'K05_V024', 'K05_V025', 'K05_V026', 'K05_V027', 'K05_V028', 'K05_V029', 'K05_V030', 'K05_V031', 'K06_V001', 'K06_V002', 'K06_V003', 'K06_V004', 'K06_V005', 'K06_V006', 'K06_V007', 'K06_V008', 'K06_V009', 'K06_V010', 'K06_V011', 'K06_V012', 'K06_V013', 'K06_V014', 'K06_V015', 'K06_V016', 'K06_V017', 'K06_V018', 'K06_V019', 'K06_V020', 'K06_V021', 'K06_V022', 'K06_V023', 'K06_V024', 'K06_V025', 'K06_V026', 'K06_V027', 'K06_V028', 'K06_V029', 'K06_V030', 'K06_V031', 'K07_V001', 'K07_V002', 'K07_V003', 'K07_V004', 'K07_V005', 'K07_V006', 'K07_V007', 'K07_V008', 'K07_V009', 'K07_V010', 'K07_V011', 'K07_V012', 'K07_V013', 'K07_V014', 'K07_V015', 'K07_V016', 'K07_V017', 'K07_V018', 'K07_V019', 'K07_V020', 'K07_V021', 'K07_V022', 'K07_V023', 'K07_V024', 'K07_V025', 'K07_V026', 'K07_V027', 'K07_V028', 'K07_V029', 'K07_V030', 'K07_V031', 'K08_V001', 'K08_V002', 'K08_V003', 'K08_V004', 'K08_V005', 'K08_V006', 'K08_V007', 'K08_V008', 'K08_V009', 'K08_V010', 'K08_V011', 'K08_V012', 'K08_V013', 'K08_V014', 'K08_V015', 'K08_V016', 'K08_V017', 'K08_V018', 'K08_V019', 'K08_V020', 'K08_V021', 'K08_V022', 'K08_V023', 'K08_V024', 'K08_V025', 'K08_V026', 'K08_V027', 'K08_V028', 'K08_V029', 'K08_V030', 'K09_V001', 'K09_V002', 'K09_V003', 'K09_V004', 'K09_V005', 'K09_V006', 'K09_V007', 'K09_V008', 'K09_V009', 'K09_V010', 'K09_V011', 'K09_V012', 'K09_V013', 'K09_V014', 'K09_V015', 'K09_V016', 'K09_V017', 'K09_V018', 'K09_V019', 'K09_V020', 'K09_V021', 'K09_V022', 'K09_V023', 'K09_V024', 'K09_V025', 'K09_V026', 'K09_V027', 'K09_V028', 'K10_V001', 'K10_V002', 'K10_V003', 'K10_V004', 'K10_V005', 'K10_V006', 'K10_V007', 'K10_V008', 'K10_V009', 'K10_V010', 'K10_V011', 'K10_V012', 'K10_V013', 'K10_V014', 'K10_V015', 'K10_V016', 'K10_V017', 'K10_V018', 'K10_V019', 'K10_V020', 'K10_V021', 'K10_V022', 'K10_V023', 'K10_V024', 'K10_V025', 'K10_V026', 'K10_V027', 'K10_V028']\n"
     ]
    }
   ],
   "source": [
    "# --- Cấu hình đường dẫn ---\n",
    "base_dir = \"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/\"\n",
    "video_path = \"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/btc-b2/media-info-aic25-b2/media-info\"\n",
    "\n",
    "# Lấy tất cả file JSON trong folder\n",
    "json_files = [f for f in os.listdir(video_path) if f.endswith(\".json\")]\n",
    "\n",
    "# Lọc video_id theo L21-L25\n",
    "video_ids = [\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in json_files\n",
    "    if os.path.splitext(f)[0][:3] in [\"K01\", \"K02\", \"K03\", \"K04\", \"K05\", \"K06\", \"K07\", \"K08\", \"K09\", \"K10\"]\n",
    "]\n",
    "\n",
    "print(\"Video IDs:\", video_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-09-05T12:03:57.99427Z",
     "iopub.status.busy": "2025-09-05T12:03:57.993956Z",
     "iopub.status.idle": "2025-09-05T12:04:02.989333Z",
     "shell.execute_reply": "2025-09-05T12:04:02.987692Z",
     "shell.execute_reply.started": "2025-09-05T12:03:57.994251Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: K01_V001: 409 keyframes\n",
      "Saved 409 keyframes for video K01_V001\n",
      "2: K01_V002: 357 keyframes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kf \u001b[38;5;129;01min\u001b[39;00m keyframes:\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Tạo text embedding\u001b[39;00m\n\u001b[32m     13\u001b[39m     text_input = build_text_for_embedding(kf)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     text_emb = \u001b[43mget_text_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     doc = {\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: kf[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     18\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text_input,\n\u001b[32m     19\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m: text_emb,   \u001b[38;5;66;03m# embedding text Qwen\u001b[39;00m\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: kf\n\u001b[32m     21\u001b[39m     }\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# print(doc)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_text_embedding\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      2\u001b[39m inputs = tokenizer(text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, truncation=\u001b[38;5;28;01mTrue\u001b[39;00m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     last_hidden_state = outputs.last_hidden_state  \u001b[38;5;66;03m# (batch, seq_len, hidden)\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Attention mask để bỏ padding\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1062\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\transformers\\models\\gemma3\\modeling_gemma3.py:555\u001b[39m, in \u001b[36mGemma3TextModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **kwargs)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    553\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\transformers\\models\\gemma3\\modeling_gemma3.py:389\u001b[39m, in \u001b[36mGemma3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_values, output_attentions, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    387\u001b[39m     position_embeddings = position_embeddings_global\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m    401\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\transformers\\models\\gemma3\\modeling_gemma3.py:334\u001b[39m, in \u001b[36mGemma3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    332\u001b[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    347\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\AI_challenge\\software\\back-end\\.venv\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:83\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.jit.is_tracing() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(is_causal, torch.Tensor):\n\u001b[32m     81\u001b[39m     is_causal = is_causal.item()\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msdpa_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Vòng lặp xử lý từng video ---\n",
    "for i, video_id in enumerate(video_ids, start=1):\n",
    "    keyframes = build_keyframes_json(base_dir, video_id)\n",
    "    print(f\"{i}: {video_id}: {len(keyframes)} keyframes\")\n",
    "\n",
    "    if len(keyframes) == 0:\n",
    "        continue\n",
    "\n",
    "    # Tính embedding text\n",
    "    all_documents = []\n",
    "    for kf in keyframes:\n",
    "        # Tạo text embedding\n",
    "        text_input = build_text_for_embedding(kf)\n",
    "        text_emb = get_text_embedding(text_input)\n",
    "    \n",
    "        doc = {\n",
    "            \"id\": kf[\"id\"],\n",
    "            \"text\": text_input,\n",
    "            \"embedding\": text_emb,   # embedding text Qwen\n",
    "            \"metadata\": kf\n",
    "        }\n",
    "        # print(doc)\n",
    "        all_documents.append(doc)\n",
    "\n",
    "\n",
    "    # Lưu JSON từng video\n",
    "    save_path = f\"C:/Users/mt200/OneDrive/Desktop/AI/AI_challenge/feature_extraction/b2/text_embedding/{video_id}.json\"\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_documents, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(all_documents)} keyframes for video {video_id}\")\n",
    "\n",
    "print(\"All videos processed.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8125331,
     "sourceId": 12846708,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8139506,
     "sourceId": 12867608,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8154228,
     "sourceId": 12888224,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8189512,
     "sourceId": 12941316,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8198310,
     "sourceId": 12954103,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8206056,
     "sourceId": 12965991,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
